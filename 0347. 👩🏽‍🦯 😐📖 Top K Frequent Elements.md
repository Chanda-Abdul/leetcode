# 347. ðŸ‘©ðŸ½â€ðŸ¦¯ ðŸ˜ðŸ“– Top K Frequent Elements
https://leetcode.com/problems/top-k-frequent-elements/

> Given an integer array `nums` and an integer `k`, return the `k` most frequent elements. You may return the answer in any order.
## Example 1:
````
Input: nums = [1,1,1,2,2,3], k = 2
Output: [1,2]
````
## Example 2:
````
Input: nums = [1], k = 1
Output: [1]
```` 

## Constraints:
- `1 <= nums.length <= 10^5`
- `k` is in the range `[1, the number of unique elements in the array]`.
- It is guaranteed that the answer is unique.
 
## Follow up
- [x] Your algorithm's <b>time complexity</b> must be better than `O(n log n)`, where `n` is the array's size.

## Approach 2: Quickselect (Hoare's selection algorithm)
### Intuition
Quickselect is a textbook algorthm typically used to solve the problems "find kth something": kth smallest, kth largest, kth most frequent, kth less frequent, etc. Like quicksort, quickselect was developed by Tony Hoare, and also known as Hoare's selection algorithm.

It has `O(N)` average time complexity and is widely used in practice. It worth noting that its worst-case time complexity is `O(N^2)`, although the probability of this worst-case is negligible.

The approach is the same as for quicksort.

One chooses a pivot and defines its position in a sorted array in a linear time using so-called partition algorithm.

As an output, we have an array where the pivot is on its perfect position in the ascending sorted array, sorted by the frequency. All elements on the left of the pivot are less frequent than the pivot, and all elements on the right are more frequent or have the same frequency.

Hence the array is now split into two parts. If by chance our pivot element took N - kth final position, then kk elements on the right are these top kk frequent we're looking for. If not, we can choose one more pivot and place it in its perfect position.
![](https://leetcode.com/problems/top-k-frequent-elements/Figures/347_rewrite/hoare.png)
 If that were a quicksort algorithm, one would have to process both parts of the array. That would result in \mathcal{O}(N \log N)O(NlogN) time complexity. In this case, there is no need to deal with both parts since one knows in which part to search for N - kth less frequent element, and that reduces the average time complexity to \mathcal{O}(N)O(N).

### Algorithm

The algorithm is quite straightforward :

Build a hash map element -> its frequency and convert its keys into the array unique of unique elements. Note that elements are unique, but their frequencies are not. That means we need a partition algorithm that works fine with duplicates.

Work with unique array. Use a partition scheme (please check the next section) to place the pivot into its perfect position pivot_index in the sorted array, move less frequent elements to the left of pivot, and more frequent or of the same frequency - to the right.

Compare pivot_index and N - k.

If pivot_index == N - k, the pivot is N - kth most frequent element, and all elements on the right are more frequent or of the same frequency. Return these top kk frequent elements.

Otherwise, choose the side of the array to proceed recursively.
`[](https://leetcode.com/problems/top-k-frequent-elements/Figures/347_rewrite/details.png)
### Lomuto's Partition Scheme

There is a zoo of partition algorithms. The most simple one is Lomuto's Partition Scheme, and so is what we will use in this article.

Here is how it works:

Move pivot at the end of the array using swap.

Set the pointer at the beginning of the array store_index = left.

Iterate over the array and move all less frequent elements to the left swap(store_index, i). Move store_index one step to the right after each swap.

Move the pivot to its final place, and return this index.

````js
function topKFrequent (nums, k) {
  const numMap = new Map()
  for(number of nums){
    numMap.set(number, (numMap.get(number) || 0)+1)
  }
  
  const mapKeys = [...numMap.keys()]
  const finalIndex = mapKeys.length-k
  
  let start = 0
  let end = mapKeys.length-1
  
  //Quicksort
  while(start <= end){
    const pivotPoint = Math.floor(Math.random() * (end-start+1)+ start)
    const pivotIndex = pivotHelper(pivotPoint, start, end)
    
    if(pivotIndex === finalIndex) {
      return mapKeys.slice(finalIndex)
    }
    if(pivotIndex < finalIndex) {
      start = pivotIndex+1
    } else {
      end = pivotIndex-1
    }
    function pivotHelper(pivotPoint, start, end){
      //move the pivotPoint to the end
      [mapKeys[pivotPoint], mapKeys[end]] = [mapKeys[end], mapKeys[pivotPoint]];
      let swapIndex = start
      
      for(let i = start; i < end; i++){
        if(numMap.get(mapKeys[i]) <numMap.get(mapKeys[end]) ){
          [mapKeys[i], mapKeys[swapIndex]] = [mapKeys[swapIndex], mapKeys[i]];
          swapIndex++
        }
      }
      [mapKeys[end], mapKeys[swapIndex]] = [mapKeys[swapIndex], mapKeys[end]];
      return swapIndex
    }
  }
};


topKFrequent ([3,0,1,0], 1)//[1,2])
topKFrequent ([1,2], 2)//[1,2])
topKFrequent ([1,1,1,2,2,3], 2)//[1,2])
topKFrequent ([1], 1)//[1]
topKFrequent ([1, 3, 2, 1, 4, 1], 2)//[1])
topKFrequent ([10, 20, 10, 20, 30, 20, 20], 3)//[20]
topKFrequent ([4, 5, 2, 4, 3, 2, 4], 2)//[1]
````
##  Complexity Analysis

- Time complexity: `O(N)` in the average case, \mathcal{O}(N^2)O(N 
2
 ) in the worst case. Please refer to this card for the good detailed explanation of Master Theorem. Master Theorem helps to get an average complexity by writing the algorithm cost as T(N) = a T(N / b) + f(N)T(N)=aT(N/b)+f(N). Here we have an example of Master Theorem case III: T(N) = T \left(\frac{N}{2}\right) + NT(N)=T( 
2
N
â€‹
 )+N, that results in `O(N)` time complexity. That's the case of random pivots.

In the worst-case of constantly bad chosen pivots, the problem is not divided by half at each step, it becomes just one element less, that leads to `O(N^2)` time complexity. It happens, for example, if at each step you choose the pivot not randomly, but take the rightmost element. For the random pivot choice the probability of having such a worst-case is negligibly small.

- Space complexity: up to `O(N)` to store hash map and array of unique elements.

###### #Blind75 #HashTable #Heap #BucketSort #Array #FaceBook
